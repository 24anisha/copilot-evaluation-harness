{
    "case_id": "case-992",
    "repo_name": "databrickslabs/dolly",
    "file_path": "training/generate.py",
    "code_snippet": "\n\n\n\ndef load_model_tokenizer_for_generate(\n\n    pretrained_model_name_or_path: str,\n\n) -> Tuple[PreTrainedModel, PreTrainedTokenizer]:\n\n    \"\"\"Loads the model and tokenizer so that it can be used for generating responses.\n\n\n\n    Args:\n\n        pretrained_model_name_or_path (str): name or path for model\n\n\n\n    Returns:\n\n        Tuple[PreTrainedModel, PreTrainedTokenizer]: model and tokenizer\n\n    \"\"\"\n\n    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, padding_side=\"left\")\n\n    model = AutoModelForCausalLM.from_pretrained(\n\n        pretrained_model_name_or_path, device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True\n\n    )\n\n    return model, tokenizer\n",
    "line_range": [
        23,
        40
    ],
    "command_specific_fields": {
        "method_name": "load_model_tokenizer_for_generate"
    },
    "language": "python",
    "commit": "e2d664ddf06e0723d818dc56d6c522ead4bd881d",
    "prompt": ""
}