{
    "case_id": "case-1185",
    "repo_name": "databrickslabs/dolly",
    "file_path": "training/trainer.py",
    "code_snippet": "\n\ndef load_tokenizer(pretrained_model_name_or_path: str = DEFAULT_INPUT_MODEL) -> PreTrainedTokenizer:\n\n    logger.info(f\"Loading tokenizer for {pretrained_model_name_or_path}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)\n\n    tokenizer.pad_token = tokenizer.eos_token\n\n    tokenizer.add_special_tokens({\"additional_special_tokens\": [END_KEY, INSTRUCTION_KEY, RESPONSE_KEY_NL]})\n\n    return tokenizer\n",
    "line_range": [
        118,
        125
    ],
    "command_specific_fields": {
        "method_name": "load_tokenizer"
    },
    "language": "python",
    "commit": "e2d664ddf06e0723d818dc56d6c522ead4bd881d",
    "prompt": ""
}