{
    "case_id": "case-0",
    "repo_name": "nock/nock",
    "file_path": "lib/playback_interceptor.js",
    "code_snippet": "{\n  const { logger } = interceptor.scope\n\n  function start() {\n    req.headers = req.getHeaders()\n\n    interceptor.scope.emit('request', req, interceptor, requestBodyString)\n\n    if (typeof interceptor.errorMessage !== 'undefined') {\n      let error\n      if (typeof interceptor.errorMessage === 'object') {\n        error = interceptor.errorMessage\n      } else {\n        error = new Error(interceptor.errorMessage)\n      }\n\n      const delay = interceptor.delayBodyInMs + interceptor.delayConnectionInMs\n      common.setTimeout(() => req.destroy(error), delay)\n      return\n    }\n\n    // This will be null if we have a fullReplyFunction,\n    // in that case status code will be set in `parseFullReplyResult`\n    response.statusCode = interceptor.statusCode\n\n    // Clone headers/rawHeaders to not override them when evaluating later\n    response.rawHeaders = [...interceptor.rawHeaders]\n    logger('response.rawHeaders:', response.rawHeaders)\n\n    // TODO: MAJOR: Don't tack the request onto the interceptor.\n    // The only reason we do this is so that it's available inside reply functions.\n    // It would be better to pass the request as an argument to the functions instead.\n    // Not adding the req as a third arg now because it should first be decided if (path, body, req)\n    // is the signature we want to go with going forward.\n    interceptor.req = req\n\n    if (interceptor.replyFunction) {\n      const parsedRequestBody = parseJSONRequestBody(req, requestBodyString)\n\n      let fn = interceptor.replyFunction\n      if (fn.length === 3) {\n        // Handle the case of an async reply function, the third parameter being the callback.\n        fn = util.promisify(fn)\n      }\n\n      // At this point `fn` is either a synchronous function or a promise-returning function;\n      // wrapping in `Promise.resolve` makes it into a promise either way.\n      Promise.resolve(fn.call(interceptor, options.path, parsedRequestBody))\n        .then(continueWithResponseBody)\n        .catch(err => req.destroy(err))\n      return\n    }\n\n    if (interceptor.fullReplyFunction) {\n      const parsedRequestBody = parseJSONRequestBody(req, requestBodyString)\n\n      let fn = interceptor.fullReplyFunction\n      if (fn.length === 3) {\n        fn = util.promisify(fn)\n      }\n\n      Promise.resolve(fn.call(interceptor, options.path, parsedRequestBody))\n        .then(continueWithFullResponse)\n        .catch(err => req.destroy(err))\n      return\n    }\n\n    if (\n      common.isContentEncoded(interceptor.headers) &&\n      !common.isStream(interceptor.body)\n    ) {\n      //  If the content is encoded we know that the response body *must* be an array\n      //  of response buffers which should be mocked one by one.\n      //  (otherwise decompressions after the first one fails as unzip expects to receive\n      //  buffer by buffer and not one single merged buffer)\n      const bufferData = Array.isArray(interceptor.body)\n        ? interceptor.body\n        : [interceptor.body]\n      const responseBuffers = bufferData.map(data => Buffer.from(data, 'hex'))\n      const responseBody = new ReadableBuffers(responseBuffers)\n      continueWithResponseBody(responseBody)\n      return\n    }\n\n    // If we get to this point, the body is either a string or an object that\n    // will eventually be JSON stringified.\n    let responseBody = interceptor.body\n\n    // If the request was not UTF8-representable then we assume that the\n    // response won't be either. In that case we send the response as a Buffer\n    // object as that's what the client will expect.\n    if (!requestBodyIsUtf8Representable && typeof responseBody === 'string') {\n      // Try to create the buffer from the interceptor's body response as hex.\n      responseBody = Buffer.from(responseBody, 'hex')\n\n      // Creating buffers does not necessarily throw errors; check for difference in size.\n      if (\n        !responseBody ||\n        (interceptor.body.length > 0 && responseBody.length === 0)\n      ) {\n        // We fallback on constructing buffer from utf8 representation of the body.\n        responseBody = Buffer.from(interceptor.body, 'utf8')\n      }\n    }\n\n    return continueWithResponseBody(responseBody)\n  }\n\n  function continueWithFullResponse(fullReplyResult) {\n    let responseBody\n    try {\n      responseBody = parseFullReplyResult(response, fullReplyResult)\n    } catch (err) {\n      req.destroy(err)\n      return\n    }\n\n    continueWithResponseBody(responseBody)\n  }\n\n  function prepareResponseHeaders(body) {\n    const defaultHeaders = [...interceptor.scope._defaultReplyHeaders]\n\n    // Include a JSON content type when JSON.stringify is called on the body.\n    // This is a convenience added by Nock that has no analog in Node. It's added to the\n    // defaults, so it will be ignored if the caller explicitly provided the header already.\n    const isJSON =\n      body !== undefined &&\n      typeof body !== 'string' &&\n      !Buffer.isBuffer(body) &&\n      !common.isStream(body)\n\n    if (isJSON) {\n      defaultHeaders.push('Content-Type', 'application/json')\n    }\n\n    response.rawHeaders.push(\n      ...selectDefaultHeaders(response.rawHeaders, defaultHeaders),\n    )\n\n    // Evaluate functional headers.\n    common.forEachHeader(response.rawHeaders, (value, fieldName, i) => {\n      if (typeof value === 'function') {\n        response.rawHeaders[i + 1] = value(req, response, body)\n      }\n    })\n\n    response.headers = common.headersArrayToObject(response.rawHeaders)\n  }\n\n  function continueWithResponseBody(rawBody) {\n    prepareResponseHeaders(rawBody)\n    const bodyAsStream = convertBodyToStream(rawBody)\n    bodyAsStream.pause()\n\n    // IncomingMessage extends Readable so we can't simply pipe.\n    bodyAsStream.on('data', function (chunk) {\n      response.push(chunk)\n    })\n    bodyAsStream.on('end', function () {\n      // https://nodejs.org/dist/latest-v10.x/docs/api/http.html#http_message_complete\n      response.complete = true\n      response.push(null)\n\n      interceptor.scope.emit('replied', req, interceptor)\n    })\n    bodyAsStream.on('error', function (err) {\n      response.emit('error', err)\n    })\n\n    const { delayBodyInMs, delayConnectionInMs } = interceptor\n\n    function respond() {\n      if (common.isRequestDestroyed(req)) {\n        return\n      }\n\n      // Even though we've had the response object for awhile at this point,\n      // we only attach it to the request immediately before the `response`\n      // event because, as in Node, it alters the error handling around aborts.\n      req.res = response\n      response.req = req\n\n      logger('emitting response')\n      req.emit('response', response)\n\n      common.setTimeout(() => bodyAsStream.resume(), delayBodyInMs)\n    }\n\n    socket.applyDelay(delayConnectionInMs)\n    common.setTimeout(respond, delayConnectionInMs)\n  }\n\n  // Calling `start` immediately could take the request all the way to the connection delay\n  // during a single microtask execution. This setImmediate stalls the playback to ensure the\n  // correct events are emitted first ('socket', 'finish') and any aborts in the queue or\n  // called during a 'finish' listener can be called.\n  common.setImmediate(() => {\n    if (!common.isRequestDestroyed(req)) {\n      start()\n    }\n  })\n}",
    "line_range": [
        113,
        325
    ],
    "command_specific_fields": {
        "method_name": "playbackInterceptor"
    },
    "language": "javascript",
    "commit": "2b7836d36c4f22f449b36ad9fd1fff2d14e9200d",
    "prompt": ""
}