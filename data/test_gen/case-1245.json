{
    "case_id": "case-1245",
    "repo_name": "databrickslabs/dolly",
    "file_path": "training/trainer.py",
    "code_snippet": "\n\ndef get_model_tokenizer(\n    pretrained_model_name_or_path: str = DEFAULT_INPUT_MODEL, *, gradient_checkpointing: bool = False\n) -> Tuple[AutoModelForCausalLM, PreTrainedTokenizer]:\n    tokenizer = load_tokenizer(pretrained_model_name_or_path)\n    model = load_model(pretrained_model_name_or_path, gradient_checkpointing=gradient_checkpointing)\n    model.resize_token_embeddings(len(tokenizer))\n\n    return model, tokenizer\n",
    "line_range": [
        136,
        145
    ],
    "command_specific_fields": {
        "method_name": "get_model_tokenizer"
    },
    "language": "python",
    "commit": "e2d664ddf06e0723d818dc56d6c522ead4bd881d",
    "prompt": ""
}