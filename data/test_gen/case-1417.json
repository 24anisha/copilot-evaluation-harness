{
    "case_id": "case-1417",
    "repo_name": "databrickslabs/dolly",
    "file_path": "training/generate.py",
    "code_snippet": "                         **kwargs)\n\n\n\n    def _sanitize_parameters(self,\n\n                             return_full_text: bool = None,\n\n                             **generate_kwargs):\n\n        preprocess_params = {}\n\n\n\n        # newer versions of the tokenizer configure the response key as a special token.  newer versions still may\n\n        # append a newline to yield a single token.  find whatever token is configured for the response key.\n\n        tokenizer_response_key = next(\n\n            (token for token in self.tokenizer.additional_special_tokens if token.startswith(RESPONSE_KEY)), None\n\n        )\n\n\n\n        response_key_token_id = None\n\n        end_key_token_id = None\n\n        if tokenizer_response_key:\n\n            try:\n\n                response_key_token_id = get_special_token_id(self.tokenizer, tokenizer_response_key)\n\n                end_key_token_id = get_special_token_id(self.tokenizer, END_KEY)\n\n\n\n                # Ensure generation stops once it generates \"### End\"\n\n                generate_kwargs[\"eos_token_id\"] = end_key_token_id\n\n            except ValueError:\n\n                pass\n\n\n\n        forward_params = generate_kwargs\n\n        postprocess_params = {\n\n            \"response_key_token_id\": response_key_token_id,\n\n            \"end_key_token_id\": end_key_token_id\n\n        }\n\n\n\n        if return_full_text is not None:\n\n            postprocess_params[\"return_full_text\"] = return_full_text\n\n\n\n        return preprocess_params, forward_params, postprocess_params\n",
    "line_range": [
        80,
        114
    ],
    "command_specific_fields": {
        "method_name": "_sanitize_parameters"
    },
    "language": "python",
    "commit": "e2d664ddf06e0723d818dc56d6c522ead4bd881d",
    "prompt": ""
}