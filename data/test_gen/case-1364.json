{
    "case_id": "case-1364",
    "repo_name": "boto/s3transfer",
    "file_path": "s3transfer/upload.py",
    "code_snippet": "        )\n\n\n\n    def yield_upload_part_bodies(self, transfer_future, chunksize):\n\n        full_file_size = transfer_future.meta.size\n\n        num_parts = self._get_num_parts(transfer_future, chunksize)\n\n        for part_number in range(1, num_parts + 1):\n\n            callbacks = self._get_progress_callbacks(transfer_future)\n\n            close_callbacks = self._get_close_callbacks(callbacks)\n\n            start_byte = chunksize * (part_number - 1)\n\n            # Get a file-like object for that part and the size of the full\n\n            # file size for the associated file-like object for that part.\n\n            fileobj, full_size = self._get_upload_part_fileobj_with_full_size(\n\n                transfer_future.meta.call_args.fileobj,\n\n                start_byte=start_byte,\n\n                part_size=chunksize,\n\n                full_file_size=full_file_size,\n\n            )\n\n\n\n            # Wrap fileobj with interrupt reader that will quickly cancel\n\n            # uploads if needed instead of having to wait for the socket\n\n            # to completely read all of the data.\n\n            fileobj = self._wrap_fileobj(fileobj)\n\n\n\n            # Wrap the file-like object into a ReadFileChunk to get progress.\n\n            read_file_chunk = self._osutil.open_file_chunk_reader_from_fileobj(\n\n                fileobj=fileobj,\n\n                chunk_size=chunksize,\n\n                full_file_size=full_size,\n\n                callbacks=callbacks,\n\n                close_callbacks=close_callbacks,\n\n            )\n\n            yield part_number, read_file_chunk\n",
    "line_range": [
        272,
        303
    ],
    "command_specific_fields": {
        "method_name": "yield_upload_part_bodies"
    },
    "language": "python",
    "commit": "da68b50bb5a6b0c342ad0d87f9b1f80ab81dffce",
    "prompt": ""
}