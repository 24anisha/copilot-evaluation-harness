{
    "case_id": "case-759",
    "repo_name": "databrickslabs/dolly",
    "file_path": "training/generate.py",
    "code_snippet": "\n\n\n\ndef get_special_token_id(tokenizer: PreTrainedTokenizer, key: str) -> int:\n\n    \"\"\"Gets the token ID for a given string that has been added to the tokenizer as a special token.\n\n\n\n    When training, we configure the tokenizer so that the sequences like \"### Instruction:\" and \"### End\" are\n\n    treated specially and converted to a single, new token.  This retrieves the token ID each of these keys map to.\n\n\n\n    Args:\n\n        tokenizer (PreTrainedTokenizer): the tokenizer\n\n        key (str): the key to convert to a single token\n\n\n\n    Raises:\n\n        ValueError: if more than one ID was generated\n\n\n\n    Returns:\n\n        int: the token ID for the given key\n\n    \"\"\"\n\n    token_ids = tokenizer.encode(key)\n\n    if len(token_ids) > 1:\n\n        raise ValueError(f\"Expected only a single token for '{key}' but found {token_ids}\")\n\n    return token_ids[0]\n",
    "line_range": [
        41,
        62
    ],
    "command_specific_fields": {
        "method_name": "get_special_token_id"
    },
    "language": "python",
    "commit": "e2d664ddf06e0723d818dc56d6c522ead4bd881d",
    "prompt": ""
}