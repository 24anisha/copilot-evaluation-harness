{
    "case_id": "case-1644",
    "repo_name": "mementum/backtrader",
    "file_path": "tools/yahoodownload.py",
    "code_snippet": "\n\n    def __init__(self, ticker, fromdate, todate, period='d', reverse=False):\n\n        try:\n\n            import requests\n\n        except ImportError:\n\n            msg = ('The new Yahoo data feed requires to have the requests '\n\n                   'module installed. Please use pip install requests or '\n\n                   'the method of your choice')\n\n            raise Exception(msg)\n\n\n\n        url = self.urlhist.format(ticker)\n\n\n\n        sesskwargs = dict()\n\n        if False and self.p.proxies:\n\n            sesskwargs['proxies'] = self.p.proxies\n\n\n\n        crumb = None\n\n        sess = requests.Session()\n\n        for i in range(self.retries + 1):  # at least once\n\n            resp = sess.get(url, **sesskwargs)\n\n            if resp.status_code != requests.codes.ok:\n\n                continue\n\n\n\n            txt = resp.text\n\n            i = txt.find('CrumbStore')\n\n            if i == -1:\n\n                continue\n\n            i = txt.find('crumb', i)\n\n            if i == -1:\n\n                continue\n\n            istart = txt.find('\"', i + len('crumb') + 1)\n\n            if istart == -1:\n\n                continue\n\n            istart += 1\n\n            iend = txt.find('\"', istart)\n\n            if iend == -1:\n\n                continue\n\n\n\n            crumb = txt[istart:iend]\n\n            crumb = crumb.encode('ascii').decode('unicode-escape')\n\n            break\n\n\n\n        if crumb is None:\n\n            self.error = 'Crumb not found'\n\n            self.f = None\n\n            return\n\n\n\n        # urldown/ticker?period1=posix1&period2=posix2&interval=1d&events=history&crumb=crumb\n\n\n\n        # Try to download\n\n        urld = '{}/{}'.format(self.urldown, ticker)\n\n\n\n        urlargs = []\n\n        posix = datetime.date(1970, 1, 1)\n\n        if todate is not None:\n\n            period2 = (todate.date() - posix).total_seconds()\n\n            urlargs.append('period2={}'.format(int(period2)))\n\n\n\n        if todate is not None:\n\n            period1 = (fromdate.date() - posix).total_seconds()\n\n            urlargs.append('period1={}'.format(int(period1)))\n\n\n\n        intervals = {\n\n            'd': '1d',\n\n            'w': '1wk',\n\n            'm': '1mo',\n\n        }\n\n\n\n        urlargs.append('interval={}'.format(intervals[period]))\n\n        urlargs.append('events=history')\n\n        urlargs.append('crumb={}'.format(crumb))\n\n\n\n        urld = '{}?{}'.format(urld, '&'.join(urlargs))\n\n        f = None\n\n        for i in range(self.retries + 1):  # at least once\n\n            resp = sess.get(urld, **sesskwargs)\n\n            if resp.status_code != requests.codes.ok:\n\n                continue\n\n\n\n            ctype = resp.headers['Content-Type']\n\n            if 'text/csv' not in ctype:\n\n                self.error = 'Wrong content type: %s' % ctype\n\n                continue  # HTML returned? wrong url?\n\n\n\n            # buffer everything from the socket into a local buffer\n\n            try:\n\n                # r.encoding = 'UTF-8'\n\n                f = io.StringIO(resp.text, newline=None)\n\n            except Exception:\n\n                continue  # try again if possible\n\n\n\n            break\n\n\n\n        self.datafile = f\n",
    "line_range": [
        50,
        144
    ],
    "command_specific_fields": {
        "method_name": "__init__"
    },
    "language": "python",
    "commit": "b853d7c90b6721476eb5a5ea3135224e33db1f14",
    "prompt": ""
}